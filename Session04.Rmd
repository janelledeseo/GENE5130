---
title: "Bioinformatics in R WGCNA"
author: "J. Deseo "
date: "Week 05: April 15th and 17th 2024"
output: 
  html_document: 
    highlight: espresso
    theme: cerulean
---

### This class will incorporate a bit of ML.

We will be performing a WGNCA, before proceeding test yourself and make sure you understand what weighted. Gene_network and correlation mean?


## The dataset.  
We will be working with the dataset "	Systems biological assessment of immunity to severe and mild COVID-19 infections" 
 
RNAseq analysis of PBMCs in a group of 17 COVID-19 subjects and 17 healthy controls


```{r setup}
    ### Edit this line so your notebook renders properly
    knitr::opts_knit$set(root.dir = normalizePath("~/KGI Spring 2024/GENE 5130 - Bioinformatics in R/R files")) 
```

We will be using the package called WGCNA, if you do not have it install, please run this cell, once it is installed comment it!
```{r}
if (!require("BiocManager", quietly = TRUE))
   install.packages("BiocManager")
BiocManager::install("WGCNA")
```

We now load the libraries
```{r message=FALSE, warning=FALSE, paged.print=FALSE, results="hide"}
# We first need to import the important library for today's class, dplyr
library(WGCNA)
library(dplyr)
library(readr)
library(DESeq2)
library(ggplot2)
```

Load the data (Counts table and metadata from canvas site)

```{r}
### Run this chunk to import the counts table and metadata into your environment.
counts <- read.csv('../data/GSE152418RawCounts.csv', header = TRUE, row.names = 1)
metadata <- read.csv('../data/GSE152418Metadata.csv', header = TRUE, row.names = 1)

```

### QC:
Here we wanna explore to see if the dataset that we have is good for analysis
We are going to use a function called goodSamplesGenes(). Use the cell below to display the help page of this function, figure out if you can run it

```{r}
gSG <- goodSamplesGenes(t(counts))

```

Subset your data so only the genes that passed the filter are kept

```{r}
new_counts <- counts[gSG$goodGenes,]

```

Another way to detect outliers is to perform hierarchical clustering of all the samples. If you do that you should be able to see if some data points are too far from the rest of the samples.

```{r}
plot(hclust(dist(t(counts)), method = 'complete'))

```
```{r}
temptree <- (hclust(dist(t(counts)), method = 'complete'))
plot(temptree)

```
```{r}
plot(hclust(dist(t(new_counts)), method = 'complete'))

```

perform hclustering on the data, **HINT!!!** Double check that columns and rows are as the program expects them!

```{r}
### Write your code here

```

Outliers are literally that samples taht are far from each other, we can also look at that by applying dimensionality reduction, one of the most common techniques is PCA. run the cell below to go to the help page for PCA

```{r}
?prcomp
```


```{r}
pcomp <- prcomp(t(new_counts))
pcomp

```


```{r}
pcomp$x
```


```{r}
ggplot(data = pcomp$x, aes(x = PC1, y = PC2)) + geom_point() + geom_text(label = rownames(pcomp$x))

```

# Filter the data to remove bad samples
**HINT** Use DPlyr

```{r}
really_good_counts <- new_counts %>%
  select(-GSM4614993) %>%
  select(-GSM4614995) %>%
  select(-GSM4615000) 
  
```

#Normalization. 

The 'easiest' way will be to run DESEq2 and use the normalized counts object from DESeq2. Look at your past notes and run it below. You have all you need but you might need to play with the metadata file.
HINT : df[!(row.names(df) %in% row_names_df_to_remove),] ### 

```{r}

### WRITE YOUR CODE HERE, ALSO RENAME THE COLUMNS OF METADATA SO IT IS EASIER TO READ, REMOVE 'DOTS' 
drop_rows <- c('GSM4614993', 'GSM4614995', 'GSM4615000')
trimmed_metadata <- metadata[!(row.names(metadata) %in% drop_rows),]

temp_rename <- rename
rename <- dplyr::rename

new_pheno <- trimmed_metadata %>%
  rename(days_post_symptom_onset = days_post_symptom_onset.ch1) %>%
  rename(disease_state = disease.state.ch1) %>%
  rename(gender = gender.ch1) %>%
  rename(geographical_location = geographical.location.ch1) %>%
  rename(severity = severity.ch1)

```


```{r}
library(DESeq2)
dds <- DESeqDataSetFromMatrix(countData = really_good_counts, 
                              colData = new_pheno,
                              design = ~ 1)

```

Now remove the genes with counts < 15 in more than 75% of samples (31*0.75 ~ 23)
This number is coming from the WGCNA recommendations

```{r}
counts(dds)
```

```{r}
dds75 <- dds[rowSums(counts(dds)) >= 23]

``` 

```{r}
dds_norm <- vst(dds75)
norm_gene_exp <- t(assay(dds_norm))

# vst = normalizes the data, takes the harmonic mean 
```

We can finally start with our WGNCA data analysis

First we pick up a soft threshold modify the power vector below 

```{r}
sft <- pickSoftThreshold(norm_gene_exp, 
                  powerVector = c(1:20), 
                  networkType = "signed", 
                  verbose = 2)
```

You can access the results with sft$fitIndices. We are going to pick a power that gives us the highest R2 and the lowest mean K. 

**HINT plot the data!** First plot Power vs r2
```{r}
### PLOT HERE
ggplot(data = sft$fitIndices, aes(x = Power, y = SFT.R.sq)) + 
  geom_point()

```

Then Plot Power vs mean.k
```{r}
#### Plot Here
### k is number of nodes, degree
### Want our network to have a low mean.k -- network should be sparse
### Only a few genes should have a lot of connections

ggplot(data = sft$fitIndices, aes(x = Power, y = mean.k.)) + 
  geom_point()
```

After you pick up a threshold we are ready to run our data analysis
```{r}
temp_cor <-  cor
cor <- WGCNA::cor
norm_gene_exp[] <- sapply(norm_gene_exp, as.numeric)

bwm <- blockwiseModules(norm_gene_exp, 
                 maxBlockSize = 5000,
                 TOMType = "signed",
                 power = 15, 
                 mergeCutHeight = 0.2, 
                 numericLabels = FALSE, 
                 randomSeed = 1234, 
                 verbose = 2)
```

bwm$colors

```{r}
# Explore the bwm object, 
# How many modules are there? 
table(bwm$colors)

# What is the largest module? -> grey


# What is the smallest? -> darkolivegreen
  
```
  
```{r}
## RUN THIS AS IS, IT WILL PLOT THE COLORS AND DENDROGRAM

mergedColors = labels2colors(bwm$colors)
plotDendroAndColors(
  bwm$dendrograms[[1]],
  mergedColors[bwm$blockGenes[[1]]],
  "Module colors",
  dendroLabels = FALSE,
  hang = 0.03,
  addGuide = TRUE,
  guideHang = 0.05 )

```

# Now we can correlate our findings with phenotypic states of patients

```{r}
new_pheno
```

```{r}
### mutate adds a new column

traits <- new_pheno_name %>%
  mutate(disease_state_bin = ifelse(grepl('COVID', disease_state),1,0)) %>%
  mutate(ICU_bin = ifelse(grepl('ICU', severity),1,0)) %>%
  mutate(severe_bin = ifelse(grepl)('Severe', severity),1,0)) %>%
  mutate(moderate_bin = ifelse(grepl)('Moderate', severity),1,0)) %>%
  mutate(convalescent_bin = ifelse(grepl)('Convalescent', severity),1,0)) %>%
  dplur::select(8:12)
traits

```

```{r}
correlations = cor(bwm$MEs, traits, use ='p')

```

```{r}
pvalues = corPvalueStudent(correlations, 31)

```

```{r}
chooseTopHubInEachModule(
  norm_gene_exp,
  mergedColors,
  omitColors = "Salmon",
  power = 15
  type = "signed"
)

### Shows the highest connectivity within those models
```

```{r}
library(Complex$Heatmap)
Heatmap(correlations)

```
